{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Forcings on CAMELs Simulations\n",
    "\n",
    "Now we can look at the output and see which forcing variables have the most error for each basin. \n",
    "This code will make one figure per basin, such that you can look at the forcing error effects in each basin separately. \n",
    "In the notebook `camels_pysumma.ipynb` you decided if you wanted to run, in order of increasing complexity: \n",
    " - 1)   `default_prob = 1`: the \"default\" configuration with the \"default\" parameters. By \"default\" we mean whatever you chose in the summa setup files. \n",
    " - 2a) `lhs_prob = 1`: the default configuration with exploration of the parameter space.\n",
    " - 2b) `config_prob = 1`: the default parameters with 8 different configurations (choices that have been seen to affect the model output in previous research) \n",
    " - 3)   `lhs_config_prob = 1`: 8 different configurations with exploration of the parameter space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Make problem complexity choices here:\n",
    "In this notebook, you can only choose one choice as 1. We suggest you choose the most complex problem you ran. \n",
    "DO NOT choose one of these to be one here if you did not choose it to be one before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will only let one variable equal 1\n",
    "default_prob = 1\n",
    "lhs_prob = 0\n",
    "config_prob = 0\n",
    "lhs_config_prob = 1\n",
    "if lhs_config_prob==1:\n",
    "    default_prob = 0\n",
    "    lhs_prob = 0\n",
    "    config_prob = 0\n",
    "elif config_prob==1:\n",
    "    default_prob = 0\n",
    "    lhs_prob = 0\n",
    "elif lhs_prob==1:\n",
    "    default_prob = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#import os\n",
    "#os.environ['PROJ_LIB']='/Users/amedin/opt/anaconda3/share/basemap'\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### You will need to edit these paths to be your folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some folder places\n",
    "home = '/glade/work/ashleyvb/CAMELs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Keep these the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_folder = home+'/summa_camels'\n",
    "settings_folder = top_folder+'/settings.v1'\n",
    "regress_folder = home+'/regress_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Summary Statistics of Error on Output\n",
    "First we need to calculate KGEs on the data, and then we summarize the results by problem complexity level.\n",
    "KGE means perfect agreement if it is 1, and <0 means the mean is a better guess. \n",
    "All data have a small number added so we don't divide by 0. \n",
    "At the start, we must do some bookkeeping of divide the decision set into each problem complexity (if we ran a bigger problem containing more than one set). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names for each set of problem complexities.\n",
    "if lhs_config_prob==1: \n",
    "    suffix = '_configs_latin.nc'\n",
    "    default_name = '++BallBerry++lightSnow++logBelowCanopy++0'\n",
    "    lat_name = [default_name[:-1]+str(i) for i in range(0,11)]\n",
    "elif lhs_prob==1:\n",
    "    suffix = '_latin.nc'\n",
    "    default_name = '0'  \n",
    "    lat_name = [str(i) for i in range(0,11)]\n",
    "elif config_prob==1:\n",
    "    suffix = '_configs.nc'\n",
    "    default_name = '++BallBerry++lightSnow++logBelowCanopy++'  \n",
    "    lat_name = default_name\n",
    "elif default_prob==1:\n",
    "    suffix = '_hru.nc'\n",
    "    default_name = 'default'\n",
    "    lat_name = default_name\n",
    "sim_truth = xr.open_dataset(top_folder+'/output/merged_day/NLDAStruth'+suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get decision names off the files\n",
    "if config_prob==1 or lhs_prob==1 or lhs_config_prob==1: decision_set = np.array(sim_truth['decision']) \n",
    "else: decision_set = np.array(['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only configuration and default param decision names, and only latin params and default configuration decision names\n",
    "ndec = len(decision_set)\n",
    "if config_prob==0: cfg_name = decision_set[range(0,ndec,11)]\n",
    "else: cfg_name = decision_set\n",
    "if lhs_config_prob==1: cfglat_name = [c[:-1]+str(i) for i in range(1,11) for c in cfg_name]\n",
    "elif lhs_prob==1: cfglat_name = lat_name\n",
    "elif config_prob==1: cfglat_name = cfg_name\n",
    "elif default_prob==1: cfglat_name = default_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we get the forcing and output names, and find the HRUs and their locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set forcings and create dictionaries\n",
    "constant_vars= ['airpres','airtemp','LWRadAtm','pptrate','spechum','SWRadAtm','windspd']\n",
    "forc_sim = constant_vars #we simulated these as output too\n",
    "comp_sim=['scalarSurfaceRunoff','scalarAquiferBaseflow','scalarInfiltration','scalarRainPlusMelt','scalarSoilDrainage',\n",
    "          'scalarLatHeatTotal','scalarSenHeatTotal','scalarSnowSublimation',\n",
    "          'scalarSWE',\n",
    "          'scalarCanopyWat',\n",
    "          'scalarNetRadiation','scalarTotalET','scalarTotalRunoff','scalarTotalSoilWat']\n",
    "var_sim = np.concatenate([forc_sim, comp_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of HRUs and small add\n",
    "attrib = xr.open_dataset(top_folder+'/settings.v1/attributes.nc')\n",
    "the_hru = np.array(attrib['hruId'])\n",
    "small_add = 1e-10 # so no zeros in KGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get lat long for plotting purposes later on\n",
    "df =  pd.read_csv(regress_folder+'/camels_topo.txt',delimiter=';')\n",
    "df['hru'] = range(0,671)\n",
    "xr_tmp = df.set_index(['hru']).to_xarray()\n",
    "xr_tmp = xr_tmp.assign_coords(hru=xr_tmp['gauge_id'])\n",
    "xr_tmp = xr_tmp.sel(hru=the_hru)\n",
    "lr_attrib = xr_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now run the actual computations on KGE. \n",
    "This can take some time. \n",
    "It takes about 1/20th of the time it took to run the whole problem, so if you ran the most complex problem with `lhs_config_prob`=1 and it took 584 minutes to complete (9 hrs, 44 min), it will take ~30 minutes to run this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions for KGE computation\n",
    "def covariance(x,y,dims=None):\n",
    "    return xr.dot(x-x.mean(dims), y-y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def correlation(x,y,dims=None):\n",
    "    return (covariance(x,y,dims)) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up xarray\n",
    "hrud = sim_truth['hru'] #indices here are 0 to number of basins\n",
    "shape = ( len(decision_set),len(hrud), len(forc_sim))\n",
    "dims = ('decision','hru','var')\n",
    "coords = {'decision':decision_set,'hru': hrud, 'var':forc_sim}\n",
    "error_data = xr.Dataset(coords=coords)\n",
    "for s in comp_sim:\n",
    "    error_data[s] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                                 coords=coords, dims=dims,\n",
    "                                 name=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "truth0_0 = sim_truth.drop_vars('hruId').load()\n",
    "for v in forc_sim:\n",
    "    truth = truth0_0\n",
    "    truth = truth.isel(time = slice(365*24,(365*6+2)*24))+small_add #don't include first year, 5 years\n",
    "    sim = xr.open_dataset(top_folder+'/output/merged_day/NLDASconstant_' + v + suffix)\n",
    "    sim = sim.drop_vars('hruId').load()\n",
    "    sim = sim.isel(time = slice(365*24,(365*6+2)*24))+small_add #don't include first year, 5 years\n",
    "    r = sim.mean(dim='time') #to set up xarray since xr.dot not supported on dataset and have to do loop\n",
    "    for s in var_sim:         \n",
    "        r[s] = correlation(sim[s],truth[s],dims='time')\n",
    "    ds = 1 - np.sqrt( np.square(r-1) \n",
    "        + np.square( sim.std(dim='time')/truth.std(dim='time') - 1) \n",
    "        + np.square( sim.mean(dim='time')/truth.mean(dim='time') - 1) )\n",
    "    ds0 = ds.load()\n",
    "    for s in comp_sim:\n",
    "        error_data[s].loc[:,:,v]  = ds0[s]\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to save it\n",
    "error_data.to_netcdf(home+'/regress_data/error_data1.nc') \n",
    "#error_data = xr.open_dataset(home+'/regress_data/error_data.nc') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Summarize this by totals over all output variables and each output variable, and ranks each constant forcing from most error to least error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup summaries by simulated output variable\n",
    "summ_kind = ['total','rank']\n",
    "shape = (len(decision_set),len(hrud),len(forc_sim),len(summ_kind))\n",
    "dims = ('decision','hru','var','summary')\n",
    "coords = {'decision':decision_set,'hru': the_hru, 'var': forc_sim,'summary':summ_kind}\n",
    "rank_data = xr.Dataset(coords=coords)\n",
    "rank_data['all'] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                                 coords=coords, dims=dims,\n",
    "                                 name='all')\n",
    "for s in comp_sim:\n",
    "    rank_data[s] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                                 coords=coords, dims=dims,\n",
    "                                 name=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sums of KGE and ranks of worst to best forcing for error over all variables\n",
    "ds = error_data\n",
    "ds =ds.fillna(0) # So don't add to total KGE    \n",
    "ds1 = ds.loc[dict(var = forc_sim)]\n",
    "ds1 = ds1.where(ds1>-0.41,-0.41) #make the very negative values be -0.41\n",
    "ds2 = sum(d for d in ds1.data_vars.values())\n",
    "rank_data['all'].loc[:,:,:,'total'] = ds2.values\n",
    "rank_data['all'].loc[:,:,:,'rank'] = ds2.rank(dim='var').values\n",
    "for s in comp_sim:\n",
    "    rank_data[s].loc[:,:,:,'total'] = ds1[s].values\n",
    "    rank_data[s].loc[:,:,:,'rank'] = ds1[s].rank(dim='var').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Make the Plots\n",
    "\n",
    "This will make a summary plot for each HRU you ran. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1=['gray','red','green','blue','orange','magenta','cyan']\n",
    "col2=['pink','purple','burlywood','aquamarine','white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots by output variable\n",
    "x = np.arange(len(comp_sim))\n",
    "xtic = np.arange(0, len(comp_sim)).tolist()\n",
    "xtic =[i+0.5 for i in xtic]\n",
    "xtics =[str(i+1) for i in xtic]\n",
    "labels = list('ABCDEFGHIJKLMN')\n",
    "compsim_lab = [c[6:] for c in comp_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots by decision\n",
    "decision_lab = ['Default','LHS 1-10','Configuration 1-8','LHS 1-10 and Con 1-8']\n",
    "decision_use = np.array([0,1,2,3])\n",
    "if lhs_prob==1: decision_used = np.array([0,1])\n",
    "elif config_prob==1: decision_used = np.array([0,2])\n",
    "elif default_prob==1: decision_used = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots by forcing\n",
    "z = np.arange(len(constant_vars))\n",
    "ztic = np.arange(0, len(constant_vars)).tolist()\n",
    "ztic =[i+0.5 for i in ztic]\n",
    "ztics =[str(i+1) for i in ztic]\n",
    "constvar_lab = ['prs','tmp','lwr','ppt','hum','swr','wnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots by config\n",
    "c = np.arange(len(constant_vars))\n",
    "ctic = np.arange(0, 8)\n",
    "ctic =[i+0.5 for i in ctic]\n",
    "ctics =[str(i+1) for i in ctic]\n",
    "labelc = list('12345678')\n",
    "cfg_lab = ['Bse','Bsl','Ble','Bll','Jse','Jsl','Jle','Jll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in the_hru:\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 30))\n",
    "\n",
    "    # ------- Draw map (Plot A) ------- #\n",
    "    sub1 = plt.subplot2grid((19,7), (0,0), colspan = 2, rowspan = 4)    # placing on grid\n",
    "\n",
    "    lat=lr_attrib['gauge_lat'].sel(hru=h)\n",
    "    lon=lr_attrib['gauge_lon'].sel(hru=h)\n",
    "    m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "        projection='lcc',resolution='l',lat_1=33,lat_2=45,lon_0=-95)\n",
    "    m.drawcoastlines(linewidth=0.5)\n",
    "    m.drawstates(linewidth=0.5, linestyle='solid', color='k')\n",
    "    m.drawcountries(linewidth=2, linestyle='solid', color='k' ) \n",
    "    x, y = m(lon, lat) \n",
    "    sub1.scatter(x,y,s=100, marker = '^', color='red') \n",
    "    plt.title('(A) Location of CAMELS Basin ' +str(h),fontsize = 15)\n",
    "    sub1.axis(\"off\")\n",
    "\n",
    "\n",
    "    # ------- KGE values for each output variable (Plot B) ------- #\n",
    "    sub2 = plt.subplot2grid((19,7), (4,0), colspan = 7, rowspan = 2)    # placing on grid\n",
    "\n",
    "    for i, s in enumerate(comp_sim):\n",
    "        data = rank_data[s].sel(hru = h,summary = 'total', decision = default_name)\n",
    "        for j,v in enumerate(constant_vars):\n",
    "            sub2.scatter(i+.1*j,data.sel(var = v),s=100, marker = 's', color=col1[j])\n",
    "\n",
    "    plt.xlim(-0.5,len(comp_sim))\n",
    "    plt.ylim(-0.46,1.05)\n",
    "    plt.xticks(xtic, labels, fontsize = 12)\n",
    "    plt.xlabel('Output Variables', fontsize = 15)\n",
    "    plt.yticks(np.arange(0, 1.01,0.5).tolist())\n",
    "    plt.ylabel('KGE', fontsize = 12)\n",
    "    plt.title('(B) KGE values for each output variable',fontsize = 15)\n",
    "\n",
    "\n",
    "    # ------- KGE range over forcing datasets (Plot C) ------- #\n",
    "    sub3 = plt.subplot2grid((19,7), (7,0), colspan = 7, rowspan = 2)   # placing on grid\n",
    "\n",
    "    decision_lab = [decision_lab[i] for i in decision_use]\n",
    "    for i, s in enumerate(comp_sim):\n",
    "        data = rank_data[s].sel(hru = h,summary = 'total')\n",
    "        for j in decision_used:\n",
    "            v = decision_lab[j]\n",
    "            if v=='Default': data2 = data.sel(decision = default_name)\n",
    "            if v=='LHS 1-10': data2 = data.sel(decision = lat_name)\n",
    "            if v=='Configuration 1-8': data2 = data.sel(decision = cfg_name)\n",
    "            if v=='LHS 1-10 and Con 1-8': data2 = data.sel(decision = cfglat_name)\n",
    "            bp = sub3.boxplot(xr.concat(data2, dim='var'),positions = [i+.2*j],widths=0.2,patch_artist=True)\n",
    "            for patch in bp['boxes']:\n",
    "                patch.set(facecolor=col2[j])  \n",
    "\n",
    "    plt.xlim(-0.5,len(comp_sim))\n",
    "    plt.ylim(-0.46,1.05)\n",
    "    plt.xticks(xtic, labels, fontsize = 12)\n",
    "    plt.xlabel('Output Variables', fontsize = 15)\n",
    "    plt.yticks(np.arange(0, 1.01,0.5).tolist())\n",
    "    plt.ylabel('KGE', fontsize = 12)\n",
    "    plt.title('(C) KGE range over forcing datasets for each output variable',fontsize = 15)\n",
    "\n",
    "\n",
    "    # ------- KGE  range over ouput variables  (Plot D) ------- #\n",
    "    sub4 = plt.subplot2grid((19,7), (10,0), colspan = 7, rowspan = 2)  # placing on grid\n",
    "\n",
    "    for i, s in enumerate(constant_vars):\n",
    "        data = rank_data[comp_sim].sel(hru = h,var = s,summary = 'total')\n",
    "        for j in decision_used:\n",
    "            v = decision_lab[j]\n",
    "            if v=='Default': data2 = data.sel(decision = default_name)\n",
    "            if v=='LHS 1-10': data2 = data.sel(decision = lat_name)\n",
    "            if v=='Configuration 1-8': data2 = data.sel(decision = cfg_name)\n",
    "            if v=='LHS 1-10 and Con 1-8': data2 = data.sel(decision = cfglat_name)\n",
    "            bp = sub4.boxplot(xr.concat(data2.to_array(), dim='decision'),positions = [i+.2*j],widths=0.2,patch_artist=True)\n",
    "\n",
    "            for patch in bp['boxes']:\n",
    "                patch.set(facecolor=col2[j])  \n",
    "\n",
    "    plt.xlim(-0.5,len(constant_vars))\n",
    "    plt.ylim(-0.46,1.05)\n",
    "    plt.xticks(ztic, constvar_lab, fontsize = 12)\n",
    "    plt.xlabel('CNST Forcing Dataset', fontsize = 15)\n",
    "    plt.yticks(np.arange(0, 1.01,0.5).tolist())\n",
    "    plt.ylabel('KGE', fontsize = 12)\n",
    "    plt.title('(D) KGE range over ouput variables for each CNST forcing dataset',fontsize = 15)\n",
    "\n",
    "\n",
    "    # ------- Relative KGE rank counts for each output variable (Plot E) ------- # \n",
    "\n",
    "    for j in np.arange(len(constant_vars)):\n",
    "        plot2 = plt.subplot2grid((19,7), (13,0+j), colspan = 1, rowspan = 2)  # placing on grid\n",
    "        data = rank_data.sel(hru = h,summary='rank',decision = cfglat_name)\n",
    "        data = data.where(data==j+1)/(j+1)\n",
    "        if default_prob==0: data = data.sum(dim='decision')\n",
    "        else: data = data.fillna(0)\n",
    "        data = data/data.sum(dim='var')\n",
    "        for i, s in enumerate(comp_sim):\n",
    "            data0 = data[s]\n",
    "            data_Master = 0\n",
    "            for jj, v in enumerate(constant_vars):\n",
    "                plt.bar(height = data0.sel(var = v), x = i+0.5, width = 0.9, color =col1[jj], bottom = data_Master)\n",
    "                data_Master = data_Master+data0.sel(var = v)\n",
    "\n",
    "        plt.xlim(-0.05,len(comp_sim)-0.05)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xticks(xtic, labels, fontsize = 12)\n",
    "        plt.yticks([], [])\n",
    "        plt.box(False)\n",
    "        plt.ylabel('Counts Rank '+str(j+1), fontsize = 12)\n",
    "\n",
    "        if j==3: plt.title('(E) Relative KGE rank counts by CNST forcing dataset for each output variable',fontsize = 15)\n",
    "        if j==3: plt.xlabel('Output Variables', fontsize = 15)\n",
    "\n",
    "\n",
    "    # ------- Relative KGE rank counts for each configuration (Plot F) ------- # \n",
    "\n",
    "    for j in np.arange(len(constant_vars)):\n",
    "        plot2 = plt.subplot2grid((19,7), (16,0+j), colspan = 1, rowspan = 2)  # placing on grid\n",
    "        data = rank_data[comp_sim].sel(hru = h,summary='rank',decision = cfglat_name)\n",
    "        data = data.where(data==j+1)/(j+1)\n",
    "        for i, s in enumerate(cfg_name):\n",
    "            if lhs_config_prob==1: data0 = data.sel(decision = [s[:-1]+str(i) for i in range(1,11)])\n",
    "            elif config_prob==1: data0 = data.sel(decision = s)\n",
    "            else: data0 = data\n",
    "            if lhs_prob==1 or lhs_config_prob==1: data0 = data0.sum(dim='decision')\n",
    "            data0 = sum(d.fillna(0) for d in data0.data_vars.values())        \n",
    "            data0 = data0/data0.sum(dim='var')    \n",
    "            data_Master = 0\n",
    "            if config_prob or lhs_config_prob ==1: ii = i\n",
    "            else: ii = 3 #default configuration only\n",
    "            for jj, v in enumerate(constant_vars):\n",
    "                plt.bar(height = data0.sel(var = v), x = ii+0.5, width = 0.9, color =col1[jj], bottom = data_Master)\n",
    "                data_Master = data_Master+data0.sel(var = v)\n",
    "\n",
    "        plt.xlim(-0.05,len(cfg_name)-0.05)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xticks(ctic, labelc, fontsize = 12)\n",
    "        plt.yticks([], [])\n",
    "        plt.box(False)\n",
    "        plt.ylabel('Counts Rank '+str(j+1), fontsize = 12)\n",
    "\n",
    "        if j==3: plt.title('(F) Relative KGE rank counts by CNST forcing dataset for each SUMMA Configuration',fontsize = 15)\n",
    "        if j==3: plt.xlabel('SUMMA Configuration', fontsize = 15)\n",
    "\n",
    "            \n",
    "    # ------- Places the Legends ------- # \n",
    "    leg1 = plt.subplot2grid((19,7), (0,2))     # Plot B legend\n",
    "    for i,s in enumerate(constvar_lab): plt.scatter([],[], color = col1[i], marker = 's', label = s)\n",
    "    plt.axis('off')\n",
    "    plt.title('Forcings',fontsize = 15)\n",
    "    plt.legend(loc = 'upper center', prop = {'size':12}, frameon = False, labelspacing = .1)\n",
    "\n",
    "    leg2 = plt.subplot2grid((19,7), (0,3))     # Plot C and D legend\n",
    "    for i,s in enumerate(decision_lab): plt.scatter([],[], color = col2[i], marker = 's', label = s)\n",
    "    plt.axis('off')\n",
    "    plt.title('SUMMA Runs',fontsize = 15)\n",
    "    plt.legend(loc = ('upper center'), prop = {'size':12}, frameon = False)\n",
    "\n",
    "    leg3 = plt.subplot2grid((19,7), (0,4))     # Plot B, C, and E legend\n",
    "    for i,s in enumerate(compsim_lab): plt.scatter([],[], color = 'black', marker ='', label = labels[i]+' '+s)\n",
    "    plt.axis('off')\n",
    "    plt.title('Output Variables',fontsize = 15)\n",
    "    plt.legend(loc = ('upper center'), prop = {'size':12}, frameon = False)\n",
    "\n",
    "    leg4 = plt.subplot2grid((19,7), (0,5))     # Plot F legend\n",
    "    for i,s in enumerate(cfg_lab): plt.scatter([],[], color = 'black', marker = '', label = labelc[i]+' '+s)\n",
    "    plt.axis('off')\n",
    "    plt.title('Configurations',fontsize = 15)\n",
    "    plt.legend(loc = ('upper center'), prop = {'size':12}, frameon = False)\n",
    "\n",
    "    \n",
    "    # ------- Prints the plot ------- #\n",
    "    # if you want to save as a png\n",
    "    plt.savefig(\"graphic.png\", bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-pysumma]",
   "language": "python",
   "name": "conda-env-miniconda3-pysumma-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
