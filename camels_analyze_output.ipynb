{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Forcings on CAMELs Simulations\n",
    "\n",
    "Now we can look at the output and see if there are any patterns across the variables or across basin characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "#import cartopy\n",
    "#import geoviews as gv\n",
    "#import geopandas as gpd\n",
    "#import holoviews as hv\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "#import seaborn as sns\n",
    "import ogr\n",
    "from scipy import stats\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 96\n",
    "#hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Load the shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = '/glade/work/ashleyvb'\n",
    "folder = top+'/CAMELs'\n",
    "folders = folder+'/summa_camels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Summary Statistics of Error on output\n",
    "Let's look at some error metrics by HRU.\n",
    "KGE means perfect agreement if it is 1, and <0 means the mean is a better guess. \n",
    "Bias means perfect aggreement if it is 0, and larger means larger error. \n",
    "All errors have 1's added so we don't divide by 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth data set\n",
    "sim_truth = xr.open_dataset(folders+'/output/merged_day/NLDAStruth_hru.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set forcings to hold at constant or MetSim and create dictionaries\n",
    "cm_vars= ['all','airpres','airtemp','LWRadAtm','pptrate','spechum','SWRadAtm','windspd']\n",
    "error_kind = ['bias','kge']\n",
    "est_kind = ['constant','metsim']\n",
    "seas_kind = ['YEAR','DJF','MAM','JJA','SON']\n",
    "#forcing, liquid water fluxes for the soil domain, turbulent heat transfer, snow, vegetation, derived \n",
    "var_sim=['airpres','airtemp','LWRadAtm','pptrate','spechum','SWRadAtm','windspd',\n",
    "          'scalarSurfaceRunoff','scalarAquiferBaseflow','scalarInfiltration','scalarRainPlusMelt','scalarSoilDrainage',\n",
    "          'scalarLatHeatTotal','scalarSenHeatTotal','scalarSnowSublimation',\n",
    "          'scalarSWE',\n",
    "          'scalarCanopyWat',\n",
    "          'scalarNetRadiation','scalarTotalET','scalarTotalRunoff','scalarTotalSoilWat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions for KGE computation\n",
    "def covariance(x,y,dims=None):\n",
    "    return xr.dot(x-x.mean(dims), y-y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def correlation(x,y,dims=None):\n",
    "    return covariance(x,y,dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up xarray\n",
    "hrud = sim_truth['hru'] #indices here are 0 to number of basins\n",
    "shape = (len(hrud), len(cm_vars),len(est_kind), len(error_kind),len(seas_kind))\n",
    "dims = ('hru','var','estimation','error','season')\n",
    "coords = {'hru': hrud, 'var':cm_vars, 'estimation':est_kind, 'error':error_kind, 'season':seas_kind}\n",
    "error_data = xr.Dataset(coords=coords)\n",
    "for s in var_sim:\n",
    "    error_data[s] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                                 coords=coords, dims=dims,\n",
    "                                 name=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now run the actual computations on KGE. This takes 35 min using all 671 basins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "truth0 = sim_truth.drop_vars('hruId').load()\n",
    "for v in cm_vars:\n",
    "    for c in est_kind:     \n",
    "        sim0 = xr.open_dataset(folders+'/output/merged_day/NLDAS' + c + '_' + v +'_hru.nc')\n",
    "        sim0 = sim0.drop_vars('hruId').load()\n",
    "        for i, t in enumerate(seas_kind):     \n",
    "            if i==0: \n",
    "                truth = truth0\n",
    "                sim = sim0\n",
    "            if i>0: \n",
    "                truth = truth0.sel(time=truth0['time.season']==t)\n",
    "                sim = sim0.sel(time=sim0['time.season']==t)\n",
    "                \n",
    "            r = sim.mean(dim='time') #to set up xarray since xr.dot not supported on dataset and have to do loop\n",
    "            for s in var_sim:         \n",
    "                r[s] = correlation(sim[s],truth[s],dims='time')\n",
    "            # KGE value for each hru, add 1 so no nan\n",
    "            ds = 1 - np.sqrt( np.square(r-1) \n",
    "                + np.square( (sim.std(dim='time')+1)/(truth.std(dim='time')+1) - 1) \n",
    "                + np.square( (sim.mean(dim='time')+1)/(truth.mean(dim='time')+1) - 1) )\n",
    "            ds0 = ds.load()\n",
    "            # bias value for each hru, add 1 so no nan\n",
    "            ds = np.abs(sim-truth)/(truth+1) \n",
    "            ds1 = ds.mean(dim='time').load()\n",
    "            for s in var_sim:\n",
    "                error_data[s].loc[:,v,c,'kge',t]  = ds0[s]\n",
    "                error_data[s].loc[:,v,c,'bias',t] = ds1[s]\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hruId as coordinates\n",
    "error_data = attrib.assign_coords(hru=sim_truth['hruId'])\n",
    "the_hru = np.array(error_data['hruId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data.to_netcdf(folder+'/regress_data/error_data.nc') #save this incase hangs up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "KGE does not need to be normalized. We plot the HRU error as stack of values, with no error plotting as a height of 1 for that color. Values less than 0 are plotted as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_data =  xr.open_dataset(folder+'/regress_data/error_data.nc') #read this incase hangs up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "x = np.arange(len(hrud))\n",
    "col_vars = ['gray','y','r','g','orange','c','m','b']\n",
    "letter = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "wid = ceil(len(var_sim)/3)\n",
    "inc = floor(len(hrud)/10)\n",
    "if inc<1: inc=1\n",
    "xtic = np.arange(1, len(hrud)+.05,inc).tolist()\n",
    "xtic =[int(i) for i in xtic]\n",
    "xtics =[str(i) for i in xtic]\n",
    "labels =[\"V\"+i for i in xtics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Just plot all-- takes 8 min. Maybe add winter, and summer if you want to see more detail. \n",
    "ind = [0]#,1,3]\n",
    "seas_kind0 = [ seas_kind[i] for i in ind]\n",
    "for c in est_kind:      \n",
    "    for t in seas_kind0:     \n",
    "        plot1 = plt.figure(1, figsize = (20,10))\n",
    "\n",
    "        for i, s in enumerate(var_sim):\n",
    "            data0 = error_data[s].loc[:,:,c,'kge',t]\n",
    "            data = data0.where(data0>0,0) #make the negative values be 0\n",
    "            data_Master = [0] * len(hrud)\n",
    "    \n",
    "            plot2 = plt.subplot(3,wid,i+1)\n",
    "            for j, v in enumerate(cm_vars):\n",
    "                plt.bar(height = data.loc[:,v], x = x, width = 1.0, color = col_vars[j], bottom = data_Master)\n",
    "                #data_Master = [m + n for m, n in zip(data_Master, data.loc[:,v])]\n",
    "                data_Master = [j+1] * len(hrud)\n",
    "         \n",
    "            plt.title('('+letter[i]+') '+s)\n",
    "            plt.ylim(0,len(cm_vars))\n",
    "            plt.xticks(xtic, labels, fontsize = 3)\n",
    "            plt.yticks(np.arange(0, len(cm_vars)+.05, 1).tolist())\n",
    "            plt.tick_params(axis = \"x\", which = \"both\", bottom = False, top = False)\n",
    "            plt.xlabel(\"CAMELS basin (v1-v671)\", fontsize = 9)\n",
    "            plt.ylabel(\"KGE\", fontsize = 9)\n",
    "\n",
    "        plt.subplots_adjust(hspace = .4)\n",
    "\n",
    "        for j, v in enumerate(cm_vars):\n",
    "            plt.scatter([],[], color = col_vars[j], label = t + '_NLDAS_' + c + '_' + v)\n",
    "        plt.figlegend(loc = 'lower right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We see that the pptrate and air pressure would be better off constant than at MetSim values (thiner orange and yellow layers in the MetSim plots), but that the air pressure does not matter in the variable calculation (except simulation of air pressure itself). Air temperature has less error in MetSim. \n",
    "By season, there is more error in the winter in both Metsim and Constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Correlations of Error and Basin Attributes\n",
    "We look at the basin attributes to see if there are any patterns with the error sizes. \n",
    "We use the Kendall non-parametric correlation based on ranks, so that error magnitude (that is likely more affected by calibrated or not calibrated parameters) is not a factor. \n",
    "The attribute file that SUMMA uses does not have many continuous variables in it, so we use the raw attribute data that would have been used to derive the SUMMA attribute file. \n",
    "TEST Budyko of each setup??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the file used by SUMMA. It does not have many values and a bunch of them are indices.  \n",
    "attrib0 = xr.open_dataset(folders+'/settings.v1/attributes.nc')\n",
    "print(attrib0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here are the attribute data\n",
    "# variables to regress, take only floats\n",
    "lr_attrib0 = attrib0.get(['hruId']) \n",
    "lr_attrib0 = lr_attrib0.assign_coords(hru=lr_attrib0['hruId'])\n",
    "file_name = ['clim','geol','hydro','soil','topo','vege']\n",
    "n_attrib = file_name\n",
    "for i, f in enumerate(file_name):\n",
    "    df = pd.read_csv(folder+'/regress_data/camels_'+f+'.txt',delimiter=';')\n",
    "    df['hru'] = range(0,671)\n",
    "    xr_tmp = df.set_index(['hru']).to_xarray()\n",
    "    xr_att = xr_tmp.drop_vars([ var for var in xr_tmp.variables if not 'float64'==xr_tmp[var].dtype ])\n",
    "    if i==0: n_attrib[i]= len(xr_att.variables)-1\n",
    "    if i>0: n_attrib[i]= len(xr_att.variables)+n_attrib[i-1]\n",
    "    lr_attrib0 =xr.merge([lr_attrib0,xr_att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hruId as coordinates, select basins and print results\n",
    "lr_attrib = attrib.assign_coords(hru=lr_attrib['hruId'])\n",
    "lr_attrib = lr_attrib0.drop('hruId').load()\n",
    "lr_attrib = lr_attrib.sel(hru=the_hru)\n",
    "attrib_kind = list(lr_attrib.variables.keys())\n",
    "print(n_attrib)\n",
    "print(lr_attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now run the regressions and plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up xarray\n",
    "attrib_num = ['clim','geol','hydro','soil','topo','vege']\n",
    "shape = (len(attrib_kind), len(cm_vars),len(est_kind), len(error_kind),len(seas_kind))\n",
    "dims = ('attrib','var','estimation','error','season')\n",
    "coords = {'attrib': attrib_kind, 'var':cm_vars, 'estimation':est_kind, 'error':error_kind, 'season':seas_kind}\n",
    "corr_data = xr.Dataset(coords=coords)\n",
    "for s in var_sim:\n",
    "    corr_data[s] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                                 coords=coords, dims=dims,\n",
    "                                 name=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_cor(x,y, pthres = 0.01, direction = False):\n",
    "    \"\"\"\n",
    "    Uses the scipy stats module to calculate a Kendall correlation test\n",
    "    :pthres: Significance of the underlying test\n",
    "    :direction: output only direction as output (-1 & 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check NA values\n",
    "    nas = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    if len(x[~nas]) < 10: # If fewer than 10 data return nan\n",
    "        return np.nan\n",
    "    if norm(x[~nas] - mean(x[~nas])) < 1e-13 * abs(mean(x[~nas])): #near constant attibute\n",
    "         return np.nan\n",
    "    if norm(y[~nas] - mean(y[~nas])) < 1e-13 * abs(mean(y[~nas])): #near constant error\n",
    "         return np.nan\n",
    "       \n",
    "    \n",
    "    # Run the kendalltau test\n",
    "    #stat, p_value = stats.kendalltau(x[~nas], y[~nas])\n",
    "    # Run the spearmanr test\n",
    "    #stat, p_value = stats.spearmanr(x[~nas], y[~nas])\n",
    "    # Run the pearsonr test\n",
    "    stat, p_value = stats.pearsonr(x[~nas], y[~nas])\n",
    "    \n",
    "    # Criterium to return results in case of Significance\n",
    "    if p_value < pthres:\n",
    "        # Check direction\n",
    "        if direction:\n",
    "            if stat < 0:\n",
    "                return -1\n",
    "            elif stat > 0:\n",
    "                return 1\n",
    "        else:\n",
    "            return stat\n",
    "    else:\n",
    "      return 0  \n",
    "\n",
    "# The function we are going to use for applying our kendall test\n",
    "def rank_correlation(x,y):\n",
    "    return xr.apply_ufunc(\n",
    "        r_cor, x , y\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#This takes ~7  min \n",
    "for a in attrib_kind:\n",
    "    ds0 = lr_attrib[a]\n",
    "    for v in cm_vars:\n",
    "        for c in est_kind:\n",
    "            for k in error_kind:\n",
    "                for t in seas_kind:\n",
    "                    for s in var_sim:\n",
    "                        ds1 = error_data[s].loc[:,v,c,k,t]\n",
    "                        value = rank_correlation(ds0.values, ds1.values)\n",
    "                        corr_data[s].loc[a,v,c,k,t] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "x = np.arange(len(attrib_kind))\n",
    "col_vars = ['gray','y','r','g','orange','c','m','b']\n",
    "letter = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "wid = ceil(len(var_sim)/3)\n",
    "xtic = n_attrib\n",
    "labels =file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Just plot all, winter, and summer for simplicity. \n",
    "ind = [0] #,1,3]\n",
    "seas_kind0 = [ seas_kind[i] for i in ind]\n",
    "for c in est_kind:      \n",
    "    for t in seas_kind0:     \n",
    "        plot1 = plt.figure(1, figsize = (20,10))\n",
    "\n",
    "        for i, s in enumerate(var_sim):\n",
    "            data0 = corr_data[s].loc[:,:,c,'kge',t]\n",
    "            #data = abs(data0)\n",
    "            data = data0\n",
    "            data_Master = [0] * len(attrib_kind)\n",
    "    \n",
    "            plot2 = plt.subplot(3,wid,i+1)\n",
    "            for j, v in enumerate(cm_vars):\n",
    "                plt.bar(height = data.loc[:,v], x = x, width = 1.0, color = col_vars[j], bottom = data_Master)\n",
    "                #data_Master = [m + n for m, n in zip(data_Master, data.loc[:,v])]\n",
    "                data_Master = [j+1] * len(attrib_kind)\n",
    "        \n",
    "            plt.title('('+letter[i]+') '+s)\n",
    "            plt.xticks(xtic, labels, fontsize = 3)\n",
    "            #plt.ylim(0,(len(cm_vars)/1.8))\n",
    "            #plt.yticks(np.arange(0, (len(cm_vars)/2.0)+.55, 0.5).tolist())\n",
    "            plt.ylim(0,len(cm_vars))\n",
    "            plt.yticks(np.arange(-0.5, len(cm_vars)+.05, 1).tolist())\n",
    "            plt.tick_params(axis = \"x\", which = \"both\", bottom = False, top = False)\n",
    "            plt.xlabel(\"CAMELS Attrib (a1-a52)\", fontsize = 9)\n",
    "            plt.ylabel(\"Pearson Correlation with KGE\", fontsize = 9)\n",
    "\n",
    "        plt.subplots_adjust(hspace = .4)\n",
    "\n",
    "        for j, v in enumerate(cm_vars):\n",
    "            plt.scatter([],[], color = col_vars[j], label = t + '_NLDAS_' + c + '_' + v)\n",
    "        plt.figlegend(loc = 'lower right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-pysumma]",
   "language": "python",
   "name": "conda-env-miniconda3-pysumma-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
