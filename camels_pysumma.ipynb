{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the SUMMA setup\n",
    "To begin, we have to regionalize the paths in the configuration files that SUMMA will use.\n",
    "This is accomplished by running a shell command. This is done by starting a line with the `!` operator.\n",
    "We simply run a script to complete the installation.\n",
    "Then, we can import some basic libraries along with `pysumma`.\n",
    "The `%pylab inline` magic command simply imports some standard scientific packages such as `numpy` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = '/glade/work/ashleyvb'\n",
    "folder = top+'/CAMELs'\n",
    "folders = folder+'/summa_camels'\n",
    "! cd /glade/work/ashleyvb/CAMELs/summa_camels; ./install_local_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check that we loaded the correct environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /glade/work/ashleyvb/miniconda3/envs/pysumma:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "pysumma                   2.0.0                     dev_0    <develop>\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list pysumma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Then we load the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pysumma as ps\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ashleyvb/miniconda3/envs/pysumma/lib/python3.8/site-packages/distributed/node.py:240: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 36089 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NCORES=48\n",
    "cluster = PBSCluster(n_workers = NCORES,\n",
    "                     cores=NCORES,\n",
    "                     processes=NCORES, \n",
    "                     memory=\"24GB\",\n",
    "                     project='UWAS0091',\n",
    "                     queue='regular',\n",
    "                     walltime='06:00:00')\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://10.148.14.116:39883' processes=48 threads=48, memory=24.00 GB>\n",
      "Job id            Name             User              Time Use S Queue\n",
      "----------------  ---------------- ----------------  -------- - -----\n",
      "2864024.chadmin1  Jupyter          ashleyvb          00:23:18 R regular         \n",
      "2865165.chadmin1  dask-worker      ashleyvb          00:02:36 R regular         \n"
     ]
    }
   ],
   "source": [
    "# Check that have workers, do not run the rest of the cells until the workers show up. \n",
    "print(client)\n",
    "!qstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br>\n",
    "\n",
    "# Interacting with SUMMA via the `Distributed` object\n",
    "\n",
    "We are running a `Distributed` object, which has multiple `Simulation` objects inside, each corresponding to some spatial chunk. \n",
    "We need to do `rm -r /glade/work/ashleyvb/CAMELs/summa_camels/.pysumma/` to clear out the distributed folders every run so permissions do not get screwed up in the loops. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Instantiating a `Distributed` object\n",
    "\n",
    "To set up a `Distributed` object you must supply several pieces of information. \n",
    "First, supply the SUMMA executable; this could be either the compiled executable on your local machine, or a docker image. \n",
    "The second piece of information is the path to the file manager, which we just created through the install script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable = top+'/summa/bin/summa.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_manager = folders+'/file_manager.txt'\n",
    "camels = ps.Distributed(executable, file_manager, num_workers=NCORES, chunk_size=8, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Manipulating the configuration of the distributed object\n",
    "\n",
    "Currrently, none of the attributes that can be changed in a SUMMA `Simulation` object cannot be altered in a `Distributed` object and the only one that can be viewed is the file manager. In the notebook that made the forcing files, we wrote file managers. \n",
    "To see a file manager, simply `print` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SUMMA_FILE_MANAGER_V1.0'    ! filemanager_version\n",
      "'/glade/work/ashleyvb/CAMELs/summa_camels/settings.v1/'    ! settings_path\n",
      "'/glade/work/ashleyvb/CAMELs/summa_camels/forcing/1hr/'    ! input_path\n",
      "'/glade/work/ashleyvb/CAMELs/summa_camels/output/1hr/'    ! output_path\n",
      "'modelDecisions.1hr.txt'    ! decisions_path\n",
      "'[notUsed]'    ! meta_time\n",
      "'[notUsed]'    ! meta_attr\n",
      "'[notUsed]'    ! meta_type\n",
      "'[notUsed]'    ! meta_force\n",
      "'[notUsed]'    ! meta_localparam\n",
      "'output_control2.txt'    ! output_control\n",
      "'[notUsed]'    ! meta_localindex\n",
      "'[notUsed]'    ! meta_basinparam\n",
      "'[notUsed]'    ! meta_basinmvar\n",
      "'../settings.v1/attributes.camels.v2.nc'    ! local_attributes\n",
      "'../settings.v1/localParamInfo.txt'    ! local_param_info\n",
      "'../settings.v1/basinParamInfo.txt'    ! basin_param_info\n",
      "'../settings.v1/forcingFileList.1hr.txt'    ! forcing_file_list\n",
      "'../settings.v1/coldState.8lyr.nc'    ! model_init_cond\n",
      "'../settings.v1/trialParams.camels.v1.nc'    ! parameter_trial\n",
      "'camels_1hr_'    ! output_prefix\n"
     ]
    }
   ],
   "source": [
    "print(camels.manager) #possible days 1980-01-01 to 2018-12-31, we are running 1986-10-01 01:00 to 1991-10-02 0:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Running pySUMMA for all Forcing Files\n",
    "\n",
    "We now run all 671 basins of pySUMMA for each set of forcing files. You can check how long it has been running by using the command `qstat -u <username>` in a terminal. Each run takes about 9 minutes. First, we start with the original NLDAS files, or the \"truth run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "camels.run('local')\n",
    "#all_status = [(n, s.status) for n, s in camels.simulations.items()] #if want to look at status if has errors\n",
    "all_ds = [s.output.load() for n, s in camels.simulations.items()] #load it into memory so faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just write it as several files instead of merging. However, if we want to merge, we can do the following.\n",
    "First, detect automatically which vars have hru vs gru dimensions (depending on what we use for output, we may not have any gru):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hru_vars = [] # variables that have hru dimension\n",
    "gru_vars = [] # variables that have gru dimension\n",
    "for ds in all_ds:\n",
    "    for name, var in ds.variables.items():\n",
    "        if 'hru' in var.dims:\n",
    "            hru_vars.append(name)\n",
    "        elif 'gru' in var.dims:\n",
    "            gru_vars.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter variables for merge, this takes seconds since we are running a limiited output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hru_ds = [ds[hru_vars] for ds in all_ds]\n",
    "gru_ds = [ds[gru_vars] for ds in all_ds]\n",
    "hru_merged = xr.concat(hru_ds, dim='hru')\n",
    "gru_merged = xr.concat(gru_ds, dim='gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hru_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hru_merged.to_netcdf(folders+'/output/merged_day/NLDAS_1hr_hru.nc')\n",
    "gru_merged.to_netcdf(folders+'/output/merged_day/NLDAS_1hr_gru.nc')\n",
    "del camels\n",
    "del all_ds \n",
    "del hru_merged\n",
    "del gru_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Here are the other runs, now as a loop. The processes are the same, but for clarity we will divide it into 2 loops, one for the constant forcings and one for the MetSim forcings. This will take about an hour for each loop using all 671 basins. We delete stuff after every run to reduce memory needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windspd\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error during the simulation! Print the `stdout` and `stderr` for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m/glade/work/ashleyvb/pysumma/pysumma/simulation.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Error'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             raise RuntimeError('There was an error during the simulation!'\n\u001b[0m\u001b[1;32m    376\u001b[0m                                \u001b[0;34m' Print the `stdout` and `stderr` for more'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                                ' information.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There was an error during the simulation! Print the `stdout` and `stderr` for more information."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Constant\n",
    "constant_vars= ['all'] #['airpres','airtemp','LWRadAtm','pptrate','spechum','SWRadAtm','windspd','all']\n",
    "for v in constant_vars:\n",
    "    ! rm -rf /glade/work/ashleyvb/CAMELs/summa_camels/.pysumma \n",
    "    file_manager = folders+'/file_manager_constant_' + v +'.txt'\n",
    "    camels = ps.Distributed(executable, file_manager, num_workers=NCORES, chunk_size=8, client=client)   \n",
    "    camels.run('local')\n",
    "    #all_status = [(n, s.status) for n, s in camels.simulations.items()] #if want to look at status if has errors\n",
    "    all_ds = [s.output.load() for n, s in camels.simulations.items()] #load it into memory so faster    \n",
    "    hru_vars = [] # variables that have hru dimension\n",
    "    gru_vars = [] # variables that have gru dimension\n",
    "    for ds in all_ds:\n",
    "        for name, var in ds.variables.items():\n",
    "            if 'hru' in var.dims:\n",
    "                hru_vars.append(name)\n",
    "            elif 'gru' in var.dims:\n",
    "                gru_vars.append(name)\n",
    "    hru_ds = [ds[hru_vars] for ds in all_ds]\n",
    "    gru_ds = [ds[gru_vars] for ds in all_ds]\n",
    "    hru_merged = xr.concat(hru_ds, dim='hru')\n",
    "    gru_merged = xr.concat(gru_ds, dim='gru')\n",
    "    hru_merged.to_netcdf(folders+'/output/merged_day/NLDASconstant_' + v +'_hru.nc')\n",
    "    gru_merged.to_netcdf(folders+'/output/merged_day/NLDASconstant_' + v +'_gru.nc')\n",
    "    del camels\n",
    "    del all_ds \n",
    "    del hru_merged\n",
    "    del gru_merged\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airpres\n",
      "airtemp\n",
      "pptrate\n",
      "spechum\n",
      "SWRadAtm\n",
      "windspd\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error during the simulation! Print the `stdout` and `stderr` for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m/glade/work/ashleyvb/pysumma/pysumma/simulation.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Error'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             raise RuntimeError('There was an error during the simulation!'\n\u001b[0m\u001b[1;32m    376\u001b[0m                                \u001b[0;34m' Print the `stdout` and `stderr` for more'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                                ' information.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There was an error during the simulation! Print the `stdout` and `stderr` for more information."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Metsim\n",
    "metsim_vars  = ['airpres','airtemp','LWRadAtm','pptrate','spechum','SWRadAtm','windspd','all']\n",
    "for v in metsim_vars:\n",
    "    ! rm -rf /glade/work/ashleyvb/CAMELs/summa_camels/.pysumma \n",
    "    file_manager = folders+'/file_manager_metsim_' + v +'.txt'\n",
    "    camels = ps.Distributed(executable, file_manager, num_workers=NCORES, chunk_size=8, client=client)   \n",
    "    camels.run('local')\n",
    "    #all_status = [(n, s.status) for n, s in camels.simulations.items()] #if want to look at status if has errors\n",
    "    all_ds = [s.output.load() for n, s in camels.simulations.items()] #load it into memory so faster    \n",
    "    hru_vars = [] # variables that have hru dimension\n",
    "    gru_vars = [] # variables that have gru dimension\n",
    "    for ds in all_ds:\n",
    "        for name, var in ds.variables.items():\n",
    "            if 'hru' in var.dims:\n",
    "                hru_vars.append(name)\n",
    "            elif 'gru' in var.dims:\n",
    "                gru_vars.append(name)\n",
    "    hru_ds = [ds[hru_vars] for ds in all_ds]\n",
    "    gru_ds = [ds[gru_vars] for ds in all_ds]\n",
    "    hru_merged = xr.concat(hru_ds, dim='hru')\n",
    "    gru_merged = xr.concat(gru_ds, dim='gru')\n",
    "    hru_merged.to_netcdf(folders+'/output/merged_day/NLDASmetsim_' + v +'_hru.nc')\n",
    "    gru_merged.to_netcdf(folders+'/output/merged_day/NLDASmetsim_' + v +'_gru.nc')\n",
    "    del camels\n",
    "    del all_ds \n",
    "    del hru_merged\n",
    "    del gru_merged\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulStart    '1980-04-02 00:00'   ! simulation start time\n",
      "simulFinsh    '1980-04-02 23:00'   ! simulation end time\n",
      "tmZoneInfo    utcTime              ! time zone information\n",
      "soilCatTbl    STAS                 ! soil-category dataset\n",
      "vegeParTbl    MODIFIED_IGBP_MODIS_NOAH ! vegetation-category dataset\n",
      "soilStress    NoahType             ! choice of function for the soil moisture control on stomatal resistance\n",
      "stomResist    BallBerry            ! choice of function for stomatal resistance\n",
      "num_method    itertive             ! choice of numerical method\n",
      "fDerivMeth    analytic             ! choice of method to calculate flux derivatives\n",
      "LAI_method    monTable             ! choice of method to determine LAI and SAI\n",
      "f_Richards    mixdform             ! form of Richards equation\n",
      "groundwatr    bigBuckt             ! choice of groundwater parameterization\n",
      "hc_profile    constant             ! choice of hydraulic conductivity profile\n",
      "bcUpprTdyn    nrg_flux             ! type of upper boundary condition for thermodynamics\n",
      "bcLowrTdyn    zeroFlux             ! type of lower boundary condition for thermodynamics\n",
      "bcUpprSoiH    liq_flux             ! type of upper boundary condition for soil hydrology\n",
      "bcLowrSoiH    drainage             ! type of lower boundary condition for soil hydrology\n",
      "veg_traits    Raupach_BLM1994      ! choice of parameterization for vegetation roughness length and displacement height\n",
      "canopyEmis    difTrans             ! choice of parameterization for canopy emissivity\n",
      "snowIncept    lightSnow            ! choice of parameterization for snow interception\n",
      "windPrfile    logBelowCanopy       ! choice of canopy wind profile\n",
      "astability    louisinv             ! choice of stability function\n",
      "canopySrad    BeersLaw             ! choice of method for canopy shortwave radiation\n",
      "alb_method    conDecay             ! choice of albedo representation\n",
      "compaction    anderson             ! choice of compaction routine\n",
      "snowLayers    CLM_2010             ! choice of method to combine and sub-divide snow layers\n",
      "thCondSnow    jrdn1991             ! choice of thermal conductivity representation for snow\n",
      "thCondSoil    funcSoilWet          ! choice of thermal conductivity representation for soil\n",
      "spatial_gw    localColumn          ! choice of method for spatial representation of groundwater\n",
      "subRouting    timeDlay             ! choice of method for sub-grid routing\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-707adcd03320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_suffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Success'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here is the code to run a smaller test set that is not in distributed mode if you have errors and want to see them.\n",
    "s = ps.Simulation(executable, file_manager)\n",
    "s.decisions['simulStart'] = '1980-04-02 00:00'\n",
    "s.decisions['simulFinsh'] = '1980-04-02 23:00'\n",
    "print(s.decisions)\n",
    "s.run('local', run_suffix='_default')\n",
    "assert s.status == 'Success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: The following floating-point exceptions are signalling: IEEE_INVALID_FLAG\n",
      "STOP 1\n",
      "\n",
      "file_suffix is '_default'.\n",
      "file_master is '/glade/work/ashleyvb/CAMELs/summa_camels/.pysumma/_default/file_manager_metsim_all.txt'.\n",
      "decisions file =  /glade/work/ashleyvb/CAMELs/summa_camels/.pysumma/_default/settings.v1/modelDecisions.1hr.txt\n",
      "   1 simulStart: 1980-04-02 00:00\n",
      "   2 simulFinsh: 1980-04-02 23:00\n",
      "   3 tmZoneInfo: utcTime\n",
      "   4 soilCatTbl: STAS\n",
      "   5 vegeParTbl: MODIFIED_IGBP_MODIS_NOAH\n",
      "   6 soilStress: NoahType\n",
      "   7 stomResist: BallBerry\n",
      "   8 num_method: itertive\n",
      "   9 fDerivMeth: analytic\n",
      "  10 LAI_method: monTable\n",
      "  11 f_Richards: mixdform\n",
      "  12 groundwatr: bigBuckt\n",
      "  13 hc_profile: constant\n",
      "  14 bcUpprTdyn: nrg_flux\n",
      "  15 bcLowrTdyn: zeroFlux\n",
      "  16 bcUpprSoiH: liq_flux\n",
      "  17 bcLowrSoiH: drainage\n",
      "  18 veg_traits: Raupach_BLM1994\n",
      "  19 canopyEmis: difTrans\n",
      "  20 snowIncept: lightSnow\n",
      "  21 windPrfile: logBelowCanopy\n",
      "  22 astability: louisinv\n",
      "  23 canopySrad: BeersLaw\n",
      "  24 alb_method: conDecay\n",
      "  25 compaction: anderson\n",
      "  26 snowLayers: CLM_2010\n",
      "  27 thCondSnow: jrdn1991\n",
      "  28 thCondSoil: funcSoilWet\n",
      "  29 spatial_gw: localColumn\n",
      "  30 subRouting: timeDlay\n",
      "startTime: iyyy, im, id, ih, imin = 1980  4  2  0  0\n",
      "finshTime: iyyy, im, id, ih, imin = 1980  4  2 23  0\n",
      "number of time steps =          24\n",
      "Skipping over LUTYPE = USGS\n",
      "\n",
      "\n",
      "WARNING: summa_readForcing/readForcingData/problem reading forcing data: \u0018M\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000                        ®`^*\u0000\u0000|\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u001c",
      "M\u0000\u0000\u001bM\u0000\u0000\u001bM\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000`^*\u0000\u0000        \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000{\u0000\u0000\u0000\u0000\u0000\u0000\u0000^\u0000\u0000\u0000\u0000        \u001c",
      "M\u0000\u0000\u001c",
      "M\u0000\u0000@\u001c",
      "M\u0000\u0000\u0000\u0000\n",
      "\n",
      " (can keep going, but stopping anyway)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(s.stderr)\n",
    "print(s.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysumma",
   "language": "python",
   "name": "pysumma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
